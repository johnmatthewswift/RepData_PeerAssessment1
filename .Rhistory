gsub('[*0]', '', '000606')
gsub('[^0]', '', '000606')
gsub('^0', '', '000606')
gsub('^0*0', '', '000606')
gsub('^0*0', '', '606')
gsub('^0*0', '', '6060')
gsub('^0*', '', '00006060')
buildingInfo <- read.table(
fullBuildingsFileName,
sep ='\t',
header = TRUE,
colClasses = c(
replicate(2, 'NULL'), 'factor', 'NULL', 'factor',
replicate(3, 'NULL'), 'character', 'character', 'character',
replicate(13, 'NULL'), 'numeric', 'NULL'
),
col.names = c(
replicate(2, 'NULL'), 'storeName', 'NULL', 'storeCodeLong',
replicate(3, 'NULL'), 'street', 'postcode', 'city',
replicate(13, 'NULL'), 'surfaceArea', 'NULL'
)
)
buildingInfo$storeCodeLong <- gsub('^0*', '', buildingInfo$storeCodeLong)
# Read Site Info file
siteInfo <- read.table(
fullSiteInfoFileName,
sep ='\t',
header = TRUE,
colClasses = c(
replicate(2, 'NULL'), 'factor', 'NULL', 'factor',
'factor', 'character', 'character', 'character',
replicate(21, 'NULL')
),
col.names = c(
replicate(2, 'NULL'), 'storeName', 'NULL', 'storeCodeShort',
'storeCodeLong', 'street', 'postcode', 'city',
replicate(21, 'NULL')
)
)
siteInfo$storeCodeShort <- gsub('^0*', '', siteInfo$storeCodeShort)
siteInfo$storeCodeLong <- gsub('^0*', '', siteInfo$storeCodeLong)
# Read Store Meters file
storeMeters <- read.table(
fullStoreMetersFileName,
sep = '\t',
header = TRUE,
colClasses = c(
replicate(3, 'factor'), 'NULL'
),
col.names = c(
'id', 'storeName', 'storeCodeLong', 'NULL'
)
)
storeMeters$storeCodeLong <- gsub('^0*', '', storeMeters$storeCodeLong)
# Read Savings File - N.B. Custom class used to read date format
setClass('savingsDT')
setAs(
'character',
'savingsDT',
function(from) as.POSIXct(from, tz='UTC', format="%d/%m/%Y")
)
savings <- read.table(
fullSavingsFileName,
sep = '\t',
header = TRUE,
colClasses = c(
'factor', 'NULL', 'NULL', 'savingsDT', 'savingsDT',
'savingsDT', replicate(8, 'NULL')
),
col.names = c(
'storeCodeShort', 'NULL', 'NULL', 'projStart', 'projStop',
'contractEnd', replicate(8, 'NULL')
)
)
savings$storeCodeShort <- gsub('^0*', '', savings$storeCodeShort)
# Read Trading Hours File
setClass('tradingT')
setAs(
'character',
'tradingT',
function(from) hm(from)
)
tradingHours <- read.table(
fullTradingHoursFileName,
sep = '\t',
header = TRUE,
colClasses = c(
'NULL', 'factor', 'NULL', 'factor', replicate(7, 'character')
),
col.names = c(
'NULL', 'storeCodeShort', 'NULL', 'state', 'sun', 'mon', 'tue',
'wed', 'thu', 'fri', 'sat'
)
)
tradingHours <- gather(tradingHours, day, time, sun:sat)
tradingHours$key <- paste0(tradingHours$day, tradingHours$state)
tradingHours$day <- NULL
tradingHours$state <- NULL
tradingHours <- spread(tradingHours, key, time)
tradingHours$storeCodeShort <- gsub(
'^0*', '', tradingHours$storeCodeShort
)
# Read Weather Map file
weatherMap <- read.table(
fullWeatherMapFileName, sep = '\t', header = TRUE,
colClasses = c('factor', 'factor', 'factor', 'factor', 'NULL'),
col.names = c(
'storeName', 'storeCodeShort', 'storeCodeLong',
'weatherStn', 'NULL'
)
)
weatherMap$storeCodeShort <- gsub('^0*', '', weatherMap$storeCodeShort)
weatherMap$storeCodeLong <- gsub('^0*', '', weatherMap$storeCodeLong)
# Merge data --------------------------------------------------------------
# Merge all time-independent information to one data frame
siteData <- merge(
siteInfo, buildingInfo, all = TRUE
)
siteData <- merge(
siteData, storeMeters, all = TRUE
)
siteData <- merge(
siteData, savings, all = TRUE
)
siteData <- merge(
siteData, tradingHours, all = TRUE
)
siteData <- merge(
siteData, weatherMap, all = TRUE
)
write.table(siteData, 'tmp.txt', sep = '\t', row.names = FALSE)
unique(siteData$storeCodeShort)
length(unique(siteData$storeCodeShort))
sum(is.na(siteData$storeCodeShort))
rm(list=ls())
library(swirl)
swirl()
library(dplyr)
cran <- tbl_df(mydf)
rm('mydf')
cran
?group_by
by_package <- group_by(cran, package)
by_package
summarize(by_package, mean(size))
submit()
pack_sum
quantile(pack_sum$count, probs = 0.99)
top_counts <- filter(pack_sum, count > 679)
top_counts
View(top_counts)
top_counts_sorted <- arrange(top_counts, desc(counts))
top_counts_sorted <- arrange(top_counts, desc(count))
View(top_counts_sorted)
quantile(pack_sum$unique, probs = 0.99))
quantile(pack_sum$unique, probs = 0.99)
top_unique <- filter(pack_sum, unique > 465)
View(top_unique)
top_unique_sorted <- arrange(top_unique, desc(unique))
View(top_unique_sorted)
submit()
submit()
submit()
View(result3)
submit()
submit(0)
submit()
submit()
submit()
submit()
setwd('..')
getwd()
rm(list=ls())
swirl()
library(tidyr)
students
?gather
gather(students, sex, count, -grade)
students2
res <- gather(students2m sex_class, column_count)
res <- gather(students2, sex_class, column_count)
res <- gather(students2, sex_class, count, - grade)
res
?separate
separate(res, sex_class)
separate(res, sex_class, c('sex', 'class'))
submit()
submit()
students3
?gather
submit()
?spread
submit()
submit()
extract_numeric("class5")
submit()
?mutate
submit()
students4
submit()
submit()
submit()
passed
failed
mutate(passed, status = 'passed')
passed <- mutate(passed, status = 'passed')
failed <- mutate(passed, status = 'failed')
failed <- mutate(failed, status = 'failed')
bind_rows(passed, failed)
sat
submit()
submit()
?separate
submit()
submit()
Sys.getlocale('LC_TIME')
library(lubridate)
help(package = lubridate)
this_day <- today()
this_day
year(this_day)
wday(this_day)
wday(this_day, label = TRUE)
this_momentnow()
this_moment <- now()
this_moment
hour(this_moment)
ymd('1989-05-17')
my_date <- ymd('1989-05-17')
my_date
class(my_date)
ymd('1989 My 17')
ymd('1989 May 17')
mdy('March 12, 1975')
dmy(25081985)
ymd('192012')
ymd('1920/1/2')
dt1
ymd_hms(dt1)
hms('03:22:14')
dt2
ymd(dt2)
update(this_moment, hours = 8, minutes = 34, seconds = 55)
this_moment
this_moment <- update(this_moment, hours = 17, minutes = 57)
this_moment
?now
now("America/New York")
now("America/New_York")
nyc <- now("America/New_York")
nyc
depart <- nyc + days(2)
depart
depart <- update(depart, hours = 17, minutes = 34)
depart
arrive <- depart + hours(15) + minutes(50)
?with_tz
arrive <- with_tz(arrive, "Asia/Hong_kong")
arrive <- with_tz(arrive, "Asia/Hong_Kong")
arrive
last_time <- myd("June 17, 2008", tz = "Singapore")
last_time <- mdy("June 17, 2008", tz = "Singapore")
last_time
?new_interval
how_long <- new_interval(last_time, arrive)
as.period(how_long)
stopwatch()
readRDS('./BEPPA/Data/Debenhams/procTimeData.rds')
conDeb <- readRDS('./BEPPA/Data/Debenhams/procTimeData.rds')
timeDeb <- conDeb
rm(conDeb)
?write.csv
write.csv(timeDeb, "tmp.csv")
library(lattice)
xyplot()
?xyplot
Depth <- equal.count(quakes$depth, number=8, overlap=.1)
xyplot(lat ~ long | Depth, data = quakes)
class(xyplot(lat ~ long | Depth, data = quakes))
library(nlme)
library(lattice)
xyplot(weight ~ Time | Diet, BodyWeight)
library(nlme)
library(lattice)
xyplot(weight ~ Time | Diet, BodyWeight)
BodyWeight
?panel.lmline()
?axis()
?text()
?panel.lmline()
library(lattice)
library(datasets)
data(airquality)
p <- xyplot(Ozone ~ Wind | factor(Month), data = airquality)
p
library(datasets)
data(airquality)
airquality = transform(airquality, Month = factor(Month))
qplot(Wind, Ozone, data = airquality, facets = . ~ Month)
library(ggplot2)
airquality = transform(airquality, Month = factor(Month))
qplot(Wind, Ozone, data = airquality, facets = . ~ Month)
qplot(Wind, Ozone, data = airquality, facets = . ~ factor(Month))
?transform
qplot(Wind, Ozone, data = airquality)
library(ggplot2)
g <- ggplot(movies, aes(votes, rating))
print(g)
qplot(votes, rating, data = movies)
qplot(votes, rating, data = movies, smooth = "loess")
qplot(votes, rating, data = movies) + stats_smooth("loess")
qplot(votes, rating, data = movies) + geom_smooth()
qplot(votes, rating, data = movies, panel = panel.loess)
?xyplot
?geom_point
?qunif
qunif(0.75)
x <- 1:4
p <- x/sum(x)
temp <- rbind(x, p)
rownames(temp) <- c("X", "Prob")
temp
temp$X*temp$Prob
p*x
sum(p*x)
0.3*0.75/((0.3*0.75)+(0.48*0.7))
?knit
library(knitr)
?knit
knit(PA1_template.Rmd)
setwd('./Coursera/reproducible_research/RepData_PeerAssessment1/')
knit(PA1_template.Rmd)
knit('PA1_template.Rmd')
?unz
read.csv(unz('./activity.zip'))
read.csv(unzip('./activity.zip'))
rawData <- read.csv(unzip('./activity.zip'))
rawData <-
read.csv(
unzip('./activity.zip'),
colClasses = c('numeric', 'POSIXct', 'numeric')
)
plot(rawData$interval)
max(rawData$interval)
max(rawData$interval)/5
24*60*12
24*12
24*60
24*12
2360/288
plot(rawData$date, rawData$interval)
24*60
?aggregate
aggregate(rawData, date, mean)
aggregate(steps ~ date, rawData, mean)
aggregate(steps ~ date, rawData, sum)
aggregate(steps ~ interval, rawData, sum)
aggDate <- aggregate(steps ~ date, rawData, sum)
mean(aggDate$steps)
mean(aggDate$steps)
meanSteps <- mean(aggDate$steps)
medianSteps <- median(aggDate$steps)
hist(aggDate$steps)
?hist
hist(
aggDate$steps,
main = 'Histogram of steps per day',
xlab = 'No. of Steps per day'
)
hist(
aggDate$steps,
breaks = 10,
main = 'Histogram of Steps per day',
xlab = 'No. of Steps per day'
)
hist(
aggDate$steps,
breaks = 10,
main = 'Histogram of Steps per day',
xlab = 'No. of Steps per day'
)
hist(
aggDate$steps,
breaks = 10,
main = 'Histogram of total steps per day',
xlab = 'Total steps per day'
)
2360/5
12*24
24*12
aggInterval <- aggregate(steps ~ interval, rawData, sum)
5*288
24*60
288*5
288*5
max(rawData$interval)
hist(rawData$interval)
2355/5
aggInterval
library(lubridate)
hm(rawData$interval)
?remainder
rawData$interval %% 60
rawData$interval%%60
rawData$interval%/%60
rawData$interval%/%100
stepData <-
read.csv(
unzip('./activity.zip'),
colClasses = c('numeric', 'POSIXct', 'numeric')
)
(stepData$interval%/%100)+(stepData$interval%%100)
(stepData$interval%%100)
(stepData$interval%/%100)+(stepData$interval%%100/60)
aggInterval$steps
aggInterval
rm(list=ls())
aggInterval
aggInterval <- aggregate(steps ~ interval, stepData, sum)
plot(
stepData <-
read.csv(
unzip('./activity.zip'),
colClasses = c('numeric', 'POSIXct', 'numeric')
)
stepData$interval <- (stepData$interval%/%100)+(stepData$interval%%100/60)
aggDate <- aggregate(steps ~ date, stepData, sum)
hist(
aggDate$steps,
breaks = 10,
main = 'Histogram of total steps per day',
xlab = 'Total steps per day'
)
meanSteps <- mean(aggDate$steps)
meanSteps
medianSteps <- median(aggDate$steps)
medianSteps
aggInterval <- aggregate(steps ~ interval, stepData, sum)
plot(
aggInterval$steps,
type ='l',
main = 'Average profile of daily activity',
xlab = '5-minute interval through the day'
)
agg$Interval
aggInterval
aggInterval <- aggregate(steps ~ interval, stepData, sum)
plot(
aggInterval$interval,
aggInterval$steps,
type ='l',
main = 'Average profile of daily activity',
xlab = '5-minute interval through the day'
)
aggInterval <- aggregate(steps ~ interval, stepData, sum)
plot(
aggInterval$interval,
aggInterval$steps,
type ='l',
main = 'Average profile of daily activity',
xlab = 'Time of the day',
ylab = '5-minute step count'
)
?plot
aggInterval <- aggregate(steps ~ interval, stepData, sum)
plot(
aggInterval$interval,
aggInterval$steps,
type ='l',
main = 'Average profile of daily activity',
xlab = 'Time of the day',
ylab = '5-minute step count',
xaxp = c(0,24,23)
)
aggInterval$interval,
aggInterval$steps,
type ='l',
main = 'Average profile of daily activity',
xlab = 'Time of the day',
ylab = '5-minute step count',
xaxp = c(0,24,25)
)
plot(
aggInterval$interval,
aggInterval$steps,
type ='l',
main = 'Average profile of daily activity',
xlab = 'Time of the day',
ylab = '5-minute step count',
xaxp = c(0,24,25)
)
plot(
aggInterval$interval,
aggInterval$steps,
type ='l',
main = 'Average profile of daily activity',
xlab = 'Time of the day',
ylab = '5-minute step count',
xaxp = c(0,24,12)
)
which(max(aggInterval$steps))
max(aggInterval$steps)
which.max(aggInterval$steps)
aggInterval$interval[which.max(aggInterval$steps)]
hour <- aggInterval$interval[which.max(aggInterval$steps)]
paste0(hour%/%1, ':', hour%%1*60)
is.na(stepData)
sum(is.na(stepData$steps))
rm(list=ls())
plot(stepData$steps)
source('~/.active-rstudio-document', echo=TRUE)
plot(stepData$steps)
